{"cells":[{"cell_type":"markdown","source":["# From data to logged models with DatascienceFunctions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"965a99c9-f02d-4da2-9cdb-886f9dad2af3"}}},{"cell_type":"markdown","source":["In this series of tutorials we will explore how to use datasciencefunctions to train and log classification models.\n\nThe `classification` and `data_processing` modules of `datasciencefunctions` contains various functions which help the user get from a dataset with features and a label to a dataset which machine learning models in PySpark/Scikit-learn can be applied to (using functions in `data_processing`) and subsequently to a trained and versioned model with predictions (using functions in the `classification` module)\n\nThe tutorials are structured as follows. The order is not strictly mandatory but you will likely miss some crucial concepts of the library if you skip the first two chapters.\n\n1. [The simplest way of using datasciencefunctions to train and log models using the wrappper function](../01_basics_of_do_datasciencing)\n2. [Advanced wrapper function features](../02_advanced_do_datasciencing)\n3. [Modular use of datasciencefunctions without the wrapper function](../03_custom_training_pipelines)\n4. [Custom hyperparameter spaces and custom model specifications in datasciencefunctions.MlModel](../04_custom_mlmodels_hyperparameter_spaces)\n\nClick on the hyperlinks to get to specific tutorials."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59e2db5c-0dc2-4ff7-a643-40b97b865e96"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"classification","dashboards":[],"language":"python","widgets":{},"notebookOrigID":278629}},"nbformat":4,"nbformat_minor":0}